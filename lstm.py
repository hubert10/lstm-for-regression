# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ybtc_UIBaOUF-EE_y4x2abRUqt3h93YM
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
from keras.models import Sequential
from keras.layers import Bidirectional, LSTM, Dropout, Dense

# Commented out IPython magic to ensure Python compatibility.

df = pd.read_csv('data/nyc_taxi.csv', engine='python')
df.head()

df.shape

# Convert the timestamp string to datetime datatype (year, month, day, hour)
df['timestamp'] = pd.to_datetime(df['timestamp'])
df.head()

# Setperating the timestamp columns into seperate columns
df['Year'] = df.timestamp.dt.year
df['Month'] = df.timestamp.dt.month
df['Day'] = df.timestamp.dt.day
df['Hour'] = df.timestamp.dt.hour
df.head()

# Checking the unique values available in each column
print('Unique number of years: ', df.Year.unique())
print('Unique number of months: ', df.Month.unique())
print('Unique number of days: ', df.Day.unique())
print('Unique number of hours: ', df.Hour.unique())

df['value'].mean()

fig, ax = plt.subplots(figsize=(12, 5))
ax.plot(df.iloc[0:7344]['timestamp'], df.iloc[0:7344]['value'])
ax.set_title('NYC Taxi Demand')
plt.xlabel('timestamp')
plt.ylabel('The Number passengers')
plt.show()

# Plotting a sample of the data
# July, 2014 ~ November 2014
df.iloc[0:7344,:].plot(y='value', x='timestamp', figsize=(15,6))

df.shape

# Plotting a sample of the data
# December, 2014 ~ January 201
df.iloc[7344:10320,:].plot(y='value', x='timestamp', figsize=(15,6))

# December 24 ~ December 25
df.iloc[8448:8544,:].plot(y='value', x='timestamp', figsize=(15,6))

# Number of readings per day
df[(df['Day'] == 1) & (df['Month'] == 7) & (df['Year'] == 2014)]

# Autocorrelation in timeseries (Weeks)
# The correlation coefficient is a measure of the linear correlation between two variables.
# 48 read per day per 7 days a week
timeLags = np.arange(1,48*7)
autoCorr = [df.value.autocorr(lag=dt) for dt in timeLags]
plt.figure(figsize=(17,7))
plt.plot(1.0/(48*7)*timeLags, autoCorr);
plt.xlabel('Time lag in weeks'); plt.ylabel('Correlation Coeff', fontsize=12);

"""# Featurization

We have created new columns from timestamp. We can also generate additional new features from the timestamp. 
- (1) Adding day of a week in addition to the day of a month
- (2) The average of rides per a particular hour for the same day of the week. 
- (3) Number of rides during the day and during the night.
"""

# (1) Adding day of the week.
df['Weekday'] = df.timestamp.dt.weekday

df.head(3)

# (2) Adding the average of rides grouped by the weekday and hour
# 7 Days, 24 Hours = 168 values
len(df[:7344].groupby(df.Weekday.astype(str) + ' ' + df.Hour.astype(str))['value'].mean().to_dict())

df['avg_hour_day'] = df.Weekday.astype(str) + ' ' + df.Hour.astype(str)
df.head(3)

df.avg_hour_day = df.avg_hour_day.replace(df[:7344].groupby(df.Weekday.astype(str) + ' ' + df.Hour.astype(str))['value'].mean().to_dict())
df.head(10)

# (3) Featuring the number of rides during the day and during the night.
# We define the day time to be any hours between 6 AM and 10 PM while Night time where usually there is less 
# demand is any time between 10:00 PM and 6:00 AM
df['day_time'] = ((df['Hour'] >= 6) & (df['Hour'] <= 22)).astype(int)

df.head()

df.groupby(['day_time']).sum().plot(kind='pie', y='value', labels=['Night Time', 'Day Time'])

sns.distplot(df.loc[df['day_time'] == 0]['value'], kde = False)
sns.distplot(df.loc[df['day_time'] == 1]['value'], kde = False);
plt.title('The number of taxi passengers', fontsize=18)
plt.xlabel('Number of passengers', fontsize=16)
plt.ylabel('Frequency', fontsize=16)

"""### Data Preperation """

df.head(3)

# Normalizing the values
standard_scaler = preprocessing.StandardScaler()
scaled_data = standard_scaler.fit_transform(df[['Hour', 'day_time', 'Weekday', 'avg_hour_day', 'value']])

scaled_df = df.copy()

scaled_df['Hour'] = scaled_data[:,0]
scaled_df['day_time'] = scaled_data[:,1]
scaled_df['Weekday'] = scaled_data[:,2]
scaled_df['avg_hour_day'] = scaled_data[:,3]
scaled_df['value'] = scaled_data[:,4]
scaled_df.head(3)

# Specifying how many values to predict
time_step = 1

"""### Splitting the dataset"""

training_size = int(len(scaled_df) * 0.9)
training, testing = scaled_df[0:training_size], scaled_df[training_size:len(df)]
print('Size of the dataset: %d' % (len(scaled_df)))
print('Training examples: %d' % (len(training)))
print('Testing examples: %d' % (len(testing)))

# training features: Value, Hour, day_time
X_train = training[['value', 'Hour', 'day_time']].to_numpy()
y_train = scaled_df[time_step:testing.index[0]]['value'].to_numpy()

# testing data
X_test = testing[0:-time_step][['value', 'Hour', 'day_time']].to_numpy()
y_test = scaled_df[testing.index[0] + time_step:]['value'].to_numpy()

fig, ax = plt.subplots(figsize=(12, 5))
ax.plot(training['timestamp'], X_train[:,0])
ax.plot(testing['timestamp'][0:-1], X_test[:,0])
ax.set_title('NYC Taxi Demand')
plt.xlabel('timestamp')
plt.ylabel('Scaled Number passengers')
plt.show()

"""### Creating the data sequence """

y_train

y_train[-X_train.shape[0]:]

# create sequences of (48-two readings per hour) data points for each training example
def create_sequence(dataset, length):
    data_sequences = []
    for index in range(len(dataset) - length):
        data_sequences.append(dataset[index: index + length])
    return np.asarray(data_sequences)

X_train = create_sequence(X_train, 48)
X_test  = create_sequence(X_test, 48)
y_train = y_train[-X_train.shape[0]:]
y_test  = y_test[-X_test.shape[0]:]

y_train[0]

fig, ax = plt.subplots(figsize=(12, 5))
ax.plot(training[0:48]['timestamp'], X_train[0,:,0])
ax.scatter(training[48:49]['timestamp'], y_train[0], color='red', linewidth=5.0)
ax.set_title('NYC Taxi Demand')
plt.xlabel('timestamp')
plt.ylabel('Scaled Number passengers')
plt.show()

fig, ax = plt.subplots(figsize=(12, 5))
ax.plot(training[1:49]['timestamp'], X_train[1,:,0])
ax.scatter(training[48:49]['timestamp'], y_train[0], color='green', linewidth=5.0)
ax.scatter(training[49:50]['timestamp'], y_train[1], color='red', linewidth=5.0)
ax.set_title('NYC Taxi Demand')
plt.xlabel('timestamp')
plt.ylabel('Scaled Number passengers')
plt.show()

print("X_train shape={}, and y_train shape={}".format(X_train.shape, y_train.shape))
print("X_test shape={}, and y_test shape={}".format(X_test.shape, y_test.shape))

"""## Model Building """

# Build the model
model = Sequential()
model.add(LSTM(64,return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[-1])))
model.add(Dropout(0.5))
model.add(LSTM(20,return_sequences=False))
model.add(Dropout(0.5))
model.add(Dense(1))
model.compile(loss='mse', optimizer='rmsprop')

# Training the model
history = model.fit(X_train, y_train, batch_size=128, epochs=50)

model.summary()

"""### Evaluation"""

# create the list of difference between prediction and test data
predictions = model.predict(X_test)
len(predictions)

def evaluate_predictions(predictions, y_test, outliers):
    ratio = []
    differences = []
    for pred in range(len(y_test)):
        ratio.append((y_test[pred]/predictions[pred])-1)
        differences.append(abs(y_test[pred]- predictions[pred]))
    
    
    n_outliers = int(len(differences) * outliers)
    outliers = pd.Series(differences).astype(float).nlargest(n_outliers)
    
    return ratio, differences, outliers

ratio, differences, outliers = evaluate_predictions(predictions, y_test, 0.01)

for index in outliers.index: 
    outliers[index] = predictions[index]
outliers

# Showing the predicted vs. actual values
fig, axs = plt.subplots()
fig.set_figheight(4)
fig.set_figwidth(15)

axs.plot(predictions,color='red', label='Predicted')
axs.plot(y_test,color='blue', label='Actual')
axs.scatter(outliers.index,outliers, color='green', linewidth=5.0, label='Outliers')
plt.xlabel('Timestamp')
plt.ylabel('Scaled number of passengers')
plt.legend(loc='upper left')
plt.show()